{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe8cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import spacy_transformers\n",
    "\n",
    "from string import punctuation\n",
    "from wordfreq import zipf_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c860a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_csv_elements_in_file(filepath):\n",
    "\n",
    "    total_elements = 0\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            total_elements += len(row)\n",
    "\n",
    "    return total_elements\n",
    "\n",
    "language = []\n",
    "total_words = []\n",
    "\n",
    "for path, subdirs, files in os.walk(\"../raw-word-list\"):\n",
    "    for name in files:\n",
    "        filename = (os.path.join(path, name))\n",
    "        language += [name.split(\".\")[0]]\n",
    "        total_words += [count_csv_elements_in_file(filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5b3119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>total_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amharic</td>\n",
       "      <td>2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>5691498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenian</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Azerbaijani</td>\n",
       "      <td>38502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Welsh</td>\n",
       "      <td>3407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Xhosa</td>\n",
       "      <td>2936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Yiddish</td>\n",
       "      <td>3603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Yoruba</td>\n",
       "      <td>2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Zulu</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        language  total_words\n",
       "0      Afrikaans         3667\n",
       "1        Amharic         2811\n",
       "2         Arabic      5691498\n",
       "3       Armenian          981\n",
       "4    Azerbaijani        38502\n",
       "..           ...          ...\n",
       "104        Welsh         3407\n",
       "105        Xhosa         2936\n",
       "106      Yiddish         3603\n",
       "107       Yoruba         2728\n",
       "108         Zulu         2983\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"language\" : language,\n",
    "    \"total_words\" : total_words\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33f2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_models = {\n",
    "    \"Catalan\": \"ca_core_news_trf\",\n",
    "    \"Croatian\": \"hr_core_news_lg\",\n",
    "    \"Danish\": \"da_core_news_trf\",\n",
    "    \"Dutch\": \"nl_core_news_lg\",\n",
    "    \"English\": \"en_core_web_trf\",\n",
    "    \"Finnish\": \"fi_core_news_lg\",\n",
    "    \"French\": \"fr_dep_news_trf\",\n",
    "    \"German\": \"de_dep_news_trf\",\n",
    "    \"Greek\": \"el_core_news_lg\",\n",
    "    \"Italian\": \"it_core_news_lg\",\n",
    "    \"Lithuanian\": \"lt_core_news_lg\",\n",
    "    \"Macedonian\": \"mk_core_news_lg\",\n",
    "    \"Norwegian\": \"nb_core_news_lg\",\n",
    "    \"Polish\": \"pl_core_news_lg\",\n",
    "    \"Portuguese\": \"pt_core_news_lg\",\n",
    "    \"Romanian\": \"ro_core_news_lg\",\n",
    "    \"Russian\": \"ru_core_news_lg\",\n",
    "    \"Slovenian\": \"sl_core_news_trf\",\n",
    "    \"Spanish\": \"es_dep_news_trf\",\n",
    "    \"Swedish\": \"sv_core_news_lg\",\n",
    "    \"Ukrainian\": \"uk_core_news_trf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    return subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "pip_check = run_cmd([sys.executable, \"-m\", \"pip\", \"--version\"])\n",
    "\n",
    "if pip_check.returncode != 0:\n",
    "    print(\"pip not found, installing pip using ensurepip...\")\n",
    "    ensure = run_cmd([sys.executable, \"-m\", \"ensurepip\", \"--upgrade\"])\n",
    "    print(ensure.stdout)\n",
    "    print(ensure.stderr)\n",
    "\n",
    "    upgrade = run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
    "    print(upgrade.stdout)\n",
    "    print(upgrade.stderr)\n",
    "\n",
    "\n",
    "spacy_check = run_cmd([sys.executable, \"-c\", \"import spacy\"])\n",
    "\n",
    "if spacy_check.returncode != 0:\n",
    "    print(\"spaCy not found, installing spaCy...\")\n",
    "    install_spacy = run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"spacy\"])\n",
    "    print(install_spacy.stdout)\n",
    "    print(install_spacy.stderr)\n",
    "\n",
    "\n",
    "for model in spacy_models.values():\n",
    "    print(f\"Downloading spaCy model: {model}\")\n",
    "    result = run_cmd([sys.executable, \"-m\", \"spacy\", \"download\", model])\n",
    "\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57c3f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13a60ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Catalan created.\n",
      "Directory Croatian created.\n",
      "Directory Danish created.\n",
      "Directory Dutch created.\n",
      "Directory English created.\n",
      "Directory Finnish created.\n",
      "Directory French created.\n",
      "Directory German created.\n",
      "Directory Greek created.\n",
      "Directory Italian created.\n",
      "Directory Lithuanian created.\n",
      "Directory Macedonian created.\n",
      "Directory Norwegian created.\n",
      "Directory Polish created.\n",
      "Directory Portuguese created.\n",
      "Directory Romanian created.\n",
      "Directory Russian created.\n",
      "Directory Slovenian created.\n",
      "Directory Spanish created.\n",
      "Directory Swedish created.\n",
      "Directory Ukrainian created.\n"
     ]
    }
   ],
   "source": [
    "for language in spacy_models.keys():\n",
    "    try:\n",
    "        os.mkdir(f\"../data/{language}\")\n",
    "        print(f\"Directory {language} created.\")\n",
    "    except:\n",
    "        print(f\"Directory {language} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f63d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_word_list(language : str) -> pd.DataFrame:    \n",
    "    with open(f\"../raw-word-list/{language}/{language}.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "        word_list = f.read().split(\",\")\n",
    "\n",
    "    word_df = pd.DataFrame({\n",
    "        \"word\" : word_list\n",
    "    })\n",
    "\n",
    "    word_df['word'] = word_df[\"word\"].str.strip(punctuation)\n",
    "\n",
    "    return word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02236246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvarks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aardwolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aardwolves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466429</th>\n",
       "      <td>Zwolle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466430</th>\n",
       "      <td>Zworykin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466431</th>\n",
       "      <td>ZZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466432</th>\n",
       "      <td>zZt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466433</th>\n",
       "      <td>ZZZ\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466434 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word\n",
       "0         aardvark\n",
       "1        aardvarks\n",
       "2         aardwolf\n",
       "3       aardwolves\n",
       "4            Aaren\n",
       "...            ...\n",
       "466429      Zwolle\n",
       "466430    Zworykin\n",
       "466431          ZZ\n",
       "466432         zZt\n",
       "466433       ZZZ\\n\n",
       "\n",
       "[466434 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_word_list(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1b3a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(spacy_models[\"English\"], disable = [\"parser\", \"ner\", \"textcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9bd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lemma(df : pd.DataFrame,\n",
    "              nlp,\n",
    "              batch_size : int = 1000) -> pd.DataFrame:\n",
    "    \n",
    "    docs = nlp.pipe(df[\"word\"].to_list(), batch_size = batch_size)\n",
    "    lemmas = [doc[0].lemma_ for doc in docs]\n",
    "    df[\"lemma\"] = pd.DataFrame(lemmas, index = df.index)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4e5f49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvarks</td>\n",
       "      <td>aardvarks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aardwolf</td>\n",
       "      <td>aardwolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aardwolves</td>\n",
       "      <td>aardwolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaren</td>\n",
       "      <td>Aaren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Abama</td>\n",
       "      <td>Abama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>abamp</td>\n",
       "      <td>abamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>abampere</td>\n",
       "      <td>abampere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>abamperes</td>\n",
       "      <td>abamperes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>abamps</td>\n",
       "      <td>abamps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word      lemma\n",
       "0     aardvark   aardvark\n",
       "1    aardvarks  aardvarks\n",
       "2     aardwolf   aardwolf\n",
       "3   aardwolves   aardwolf\n",
       "4        Aaren      Aaren\n",
       "..         ...        ...\n",
       "95       Abama      Abama\n",
       "96       abamp      abamp\n",
       "97    abampere   abampere\n",
       "98   abamperes  abamperes\n",
       "99      abamps     abamps\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_lemma(\n",
    "    load_and_clean_word_list(\"English\")[:100], nlp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad726c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_word_frequencies(df : pd.DataFrame,\n",
    "                         language : str)-> pd.DataFrame :\n",
    "    \n",
    "    language_group = spacy_models[language].split(\"_\")[0]\n",
    "    df[\"zipf_freq_lemma\"] = [zipf_frequency(w, language_group) for w in df[\"lemma\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b06ad523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>zipf_freq_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>aardvark</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvarks</td>\n",
       "      <td>aardvarks</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aardwolf</td>\n",
       "      <td>aardwolf</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aardwolves</td>\n",
       "      <td>aardwolf</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaren</td>\n",
       "      <td>Aaren</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Abama</td>\n",
       "      <td>Abama</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>abamp</td>\n",
       "      <td>abamp</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>abampere</td>\n",
       "      <td>abampere</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>abamperes</td>\n",
       "      <td>abamperes</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>abamps</td>\n",
       "      <td>abamps</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word      lemma  zipf_freq_lemma\n",
       "0     aardvark   aardvark             2.39\n",
       "1    aardvarks  aardvarks             1.68\n",
       "2     aardwolf   aardwolf             1.11\n",
       "3   aardwolves   aardwolf             1.11\n",
       "4        Aaren      Aaren             0.00\n",
       "..         ...        ...              ...\n",
       "95       Abama      Abama             0.00\n",
       "96       abamp      abamp             0.00\n",
       "97    abampere   abampere             0.00\n",
       "98   abamperes  abamperes             0.00\n",
       "99      abamps     abamps             0.00\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_word_frequencies(\n",
    "    add_lemma(\n",
    "        load_and_clean_word_list(\"English\")[:100], nlp\n",
    "    ), \"English\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "971e3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_and_export(df : pd.DataFrame, language : str) -> None:\n",
    "    df = (\n",
    "        df.loc[df.groupby(\"lemma\", sort = False)[\"zipf_freq_lemma\"].idxmax()]\n",
    "        .reset_index(drop = True)\n",
    "    )\n",
    "\n",
    "    df = df[(df[\"zipf_freq_lemma\"] > 0)]\n",
    "\n",
    "    df.loc[:, \"word_difficulty\"] = pd.cut(\n",
    "        df[\"zipf_freq_lemma\"],\n",
    "        bins = [-float(\"inf\"), 2.0, 4.0, float(\"inf\")],\n",
    "        labels = [\"advanced\", \"intermediate\", \"beginner\"],\n",
    "        include_lowest = True,\n",
    "        right = True\n",
    "    )\n",
    "\n",
    "    df = df.drop(columns = [\"word\", \"zipf_freq_lemma\"])\n",
    "    df = df.rename(columns = {\n",
    "        \"lemma\" : \"word\"\n",
    "    })\n",
    "\n",
    "    df.to_json(f\"../data/{language}/word-list-cleaned.json\", orient = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d391ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up_and_export(\n",
    "    add_word_frequencies(\n",
    "        add_lemma(\n",
    "            load_and_clean_word_list(\"English\")[:100], nlp\n",
    "        ), \"English\"\n",
    "    ), \"English\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b74ec1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_word_list(language : str) -> None:\n",
    "\n",
    "    nlp = spacy.load(spacy_models[language], disable = [\"parser\", \"ner\", \"textcat\"])\n",
    "\n",
    "    print(\"Load in dataset\")\n",
    "    lang_df = load_and_clean_word_list(language)\n",
    "\n",
    "    print(\"Lemmatise Words\")\n",
    "    lang_df = add_lemma(lang_df, nlp)\n",
    "\n",
    "    print(\"Add the word frequencies\")\n",
    "    lang_df = add_word_frequencies(lang_df, language)\n",
    "\n",
    "    print(\"Do the final clean ups and export the file\")\n",
    "    clean_up_and_export(lang_df, language)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e06a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_languages(spacy_models: dict):\n",
    "    for language in spacy_models.keys():\n",
    "        print(f\"Processing language: {language}\")\n",
    "        create_clean_word_list(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b7cdb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing language: Catalan\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Croatian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Danish\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Dutch\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: English\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Finnish\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: French\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: German\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Greek\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Italian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Lithuanian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Macedonian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Norwegian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Polish\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Portuguese\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Romanian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Russian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Slovenian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Spanish\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Swedish\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n",
      "Processing language: Ukrainian\n",
      "Load in dataset\n",
      "Lemmatise Words\n",
      "Add the word frequencies\n",
      "Do the final clean ups and export the file\n"
     ]
    }
   ],
   "source": [
    "process_all_languages(spacy_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83707a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "language_raw = []\n",
    "total_words_raw = []\n",
    "\n",
    "for path, subdirs, files in os.walk(\"../raw-word-list\"):\n",
    "    for name in files:\n",
    "        filename = (os.path.join(path, name))\n",
    "        language_raw += [name.split(\".\")[0]]\n",
    "        total_words_raw += [count_csv_elements_in_file(filename)]\n",
    "\n",
    "raw_data = pd.DataFrame({\n",
    "    \"language\": language_raw,\n",
    "    \"type\": [\"Raw\"] *  len(total_words_raw),\n",
    "    \"total_words_raw\": total_words_raw,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9096a8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>type</th>\n",
       "      <th>total_words_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>Raw</td>\n",
       "      <td>3667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amharic</td>\n",
       "      <td>Raw</td>\n",
       "      <td>2811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>Raw</td>\n",
       "      <td>5691498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenian</td>\n",
       "      <td>Raw</td>\n",
       "      <td>981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Azerbaijani</td>\n",
       "      <td>Raw</td>\n",
       "      <td>38502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Welsh</td>\n",
       "      <td>Raw</td>\n",
       "      <td>3407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Xhosa</td>\n",
       "      <td>Raw</td>\n",
       "      <td>2936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Yiddish</td>\n",
       "      <td>Raw</td>\n",
       "      <td>3603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Yoruba</td>\n",
       "      <td>Raw</td>\n",
       "      <td>2728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Zulu</td>\n",
       "      <td>Raw</td>\n",
       "      <td>2983.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        language type  total_words_raw\n",
       "0      Afrikaans  Raw           3667.0\n",
       "1        Amharic  Raw           2811.0\n",
       "2         Arabic  Raw        5691498.0\n",
       "3       Armenian  Raw            981.0\n",
       "4    Azerbaijani  Raw          38502.0\n",
       "..           ...  ...              ...\n",
       "104        Welsh  Raw           3407.0\n",
       "105        Xhosa  Raw           2936.0\n",
       "106      Yiddish  Raw           3603.0\n",
       "107       Yoruba  Raw           2728.0\n",
       "108         Zulu  Raw           2983.0\n",
       "\n",
       "[109 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_clean = []\n",
    "total_words_clean = []\n",
    "\n",
    "for path, subdirs, files in os.walk(\"data\"):\n",
    "    for name in files:\n",
    "        filename = (os.path.join(path, name))\n",
    "        language_clean += [path.split(\"/\")[1]]\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            total_words_clean += [len(data.keys())]\n",
    "\n",
    "clean_data = pd.DataFrame({\n",
    "    \"language\": language_clean,\n",
    "    \"type\": [\"Clean\"] * len(total_words_clean),\n",
    "    \"total_words_raw\": total_words_clean,\n",
    "})\n",
    "\n",
    "pd.concat([raw_data, clean_data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lumen-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
